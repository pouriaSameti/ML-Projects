{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id  item_id  rating\n0      196      242       3\n1      186      302       3\n2       22      377       1\n3      244       51       2\n4      166      346       1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>196</td>\n      <td>242</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>186</td>\n      <td>302</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22</td>\n      <td>377</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>244</td>\n      <td>51</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>166</td>\n      <td>346</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download movie lens 100k dataset\n",
    "\n",
    "# !wget http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "# !unzip ml-100k.zip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "ratings = pd.read_csv('ml-100k/u.data', sep='\\t', header=None, names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "ratings.drop('timestamp', axis=1, inplace=True)\n",
    "ratings.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#perform some preprocessing to encode users and movies as integer indices.\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "ratings['user_id'] = le.fit_transform(ratings['user_id'])\n",
    "ratings['item_id'] = le.fit_transform(ratings['item_id'])"
   ],
   "metadata": {
    "id": "YogeDhWIckiy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# prompt: Prepare training and validation data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(ratings, test_size=0.2)\n",
    "train_data.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "yBO4CNoGdcYG",
    "outputId": "d217a9c1-c05a-4189-c07e-6cb99a90757a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "       user_id  item_id  rating\n85678      477      149       4\n86962      549      248       4\n42076      642      281       3\n17958      434      251       2\n23488      293      346       5",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>85678</th>\n      <td>477</td>\n      <td>149</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>86962</th>\n      <td>549</td>\n      <td>248</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>42076</th>\n      <td>642</td>\n      <td>281</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>17958</th>\n      <td>434</td>\n      <td>251</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>23488</th>\n      <td>293</td>\n      <td>346</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 943, Number of Movies: 1653, Min rating: 1, Max rating: 5\n"
     ]
    }
   ],
   "source": [
    "num_users = len(train_data.user_id.unique())\n",
    "num_movies = len(train_data.item_id.unique())\n",
    "min_rating = train_data['rating'].min()\n",
    "max_rating = train_data['rating'].max()\n",
    "print(     \"Number of users: {}, Number of Movies: {}, Min rating: {}, Max rating: {}\".format(         num_users, num_movies, min_rating, max_rating     ) )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def set_label(data: pd.DataFrame):\n",
    "    return 1 if data.rating >= 3 else 0\n",
    "\n",
    "train_data['target'] = train_data.apply(lambda x: 1 if x['rating'] >= 3 else 0, axis=1)\n",
    "test_data['target'] = test_data.apply(lambda x: 1 if x['rating'] >= 3 else 0, axis=1)\n",
    "\n",
    "x_train = train_data.drop(columns='target')\n",
    "y_train = train_data['target']\n",
    "\n",
    "x_test = test_data.drop(columns='target')\n",
    "y_test = test_data['target']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class Network:\n",
    "\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int):\n",
    "        self.__input_size = input_size\n",
    "        self.__hidden_size = hidden_size\n",
    "        self.__output_size = output_size\n",
    "\n",
    "        self.W1 = np.zeros((self.__hidden_size, self.__input_size))\n",
    "        self.b1 = np.zeros((self.__hidden_size,1))\n",
    "\n",
    "        self.W2 = np.zeros((self.__output_size, self.__hidden_size))\n",
    "        self.b2 = np.zeros((self.__output_size,1))\n",
    "\n",
    "        self.z1 = None\n",
    "        self.z2 = None\n",
    "\n",
    "    def fit(self, x_input: pd.DataFrame, y_input: pd.DataFrame, iteration=100, learning_rate=0.1):\n",
    "\n",
    "        y_input_one_hot = pd.get_dummies(y_input).to_numpy()\n",
    "        x_input = x_input.to_numpy()\n",
    "        m = y_input_one_hot.shape[0]\n",
    "\n",
    "        for _ in range(iteration):\n",
    "\n",
    "            #first layer\n",
    "            self.z1 = np.matmul(x_input, self.W1.T).T\n",
    "            self.z1 += self.b1\n",
    "\n",
    "            #second layer\n",
    "            a1 = self.leaky_relu(self.z1)\n",
    "            self.z2 = np.matmul(a1.T, self.W2.T).T\n",
    "            self.z2 += self.b2\n",
    "\n",
    "            y_pred = self.softmax(self.z2)\n",
    "\n",
    "            loss = self.compute_loss(y_real=y_input, y_predicted=y_pred)\n",
    "            print(np.sum(loss))\n",
    "\n",
    "            a2 =  self.z2\n",
    "\n",
    "            #Derivatives\n",
    "            dz2 = a2 - y_input_one_hot.T\n",
    "            dw2 = (1/m) * np.matmul(dz2, a1.T)\n",
    "            db2 = (1/m) * np.sum(dz2)\n",
    "\n",
    "\n",
    "            da1 = np.matmul(self.W2.T, dz2)\n",
    "            dz1 = da1 * np.vectorize(self.leaky_relu_derivative)(self.z1)\n",
    "            dw1 = (1/m) * np.matmul(dz1, x_input)\n",
    "            db1 = (1./m) * np.sum(dz1)\n",
    "\n",
    "\n",
    "            # Gradient Descent\n",
    "            self.W1 = self.W1 - learning_rate * dw1\n",
    "            self.W2 = self.W2 - learning_rate * dw2\n",
    "\n",
    "            self.b1 = self.b1 - learning_rate * db1\n",
    "            self.b2 = self.b2 - learning_rate * db2\n",
    "\n",
    "\n",
    "    def predict(self, x_input: pd.DataFrame):\n",
    "        z1 = np.matmul(x_input, self.W1.T).T\n",
    "        z1 += self.b1\n",
    "\n",
    "        #second layer\n",
    "        a1 = np.vectorize(self.leaky_relu)(z1)\n",
    "        z2 = np.matmul(a1.T, self.W2.T).T\n",
    "        z2 += self.b2\n",
    "        return np.argmax(self.softmax(z2), axis=0)\n",
    "\n",
    "    @classmethod\n",
    "    def leaky_relu(cls, x, alpha=0.01):\n",
    "        return np.maximum(x*alpha, alpha)\n",
    "\n",
    "    @classmethod\n",
    "    def leaky_relu_derivative(cls, x, alpha=0.01):\n",
    "        return 1.0 if x >= 0.0 else alpha\n",
    "\n",
    "    @classmethod\n",
    "    def softmax(cls, x):\n",
    "        return np.exp(x)/np.sum(np.exp(x))\n",
    "\n",
    "    @classmethod\n",
    "    def compute_loss(cls, y_real, y_predicted: pd.DataFrame):\n",
    "        y_real_one_hot = pd.get_dummies(y_real)\n",
    "\n",
    "        loss_sum = np.sum(np.multiply(y_real_one_hot.T, np.log(y_predicted)))\n",
    "        m = y_real_one_hot.shape[0]\n",
    "        loss = -(1/m) * loss_sum\n",
    "        return loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "nn = Network(input_size=3, hidden_size=64, output_size=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.985245304434827\n",
      "11.98514886971152\n",
      "11.985052499897105\n",
      "11.984956194943072\n",
      "11.984859954800964\n",
      "11.984763779422348\n",
      "11.984667668758838\n",
      "11.984571622762092\n",
      "11.98447564138379\n",
      "11.984379724575659\n",
      "11.984283872289469\n",
      "11.984188084477015\n",
      "11.98409236109014\n",
      "11.983996702080724\n",
      "11.983901107400676\n",
      "11.983805577001956\n",
      "11.983710110836558\n",
      "11.983614708856502\n",
      "11.98351937101387\n",
      "11.983424097260752\n",
      "11.983328887549295\n",
      "11.98323374183168\n",
      "11.983138660060128\n",
      "11.983043642186896\n",
      "11.982948688164264\n",
      "11.982853797944577\n",
      "11.982758971480195\n",
      "11.98266420872353\n",
      "11.982569509627016\n",
      "11.982474874143147\n",
      "11.982380302224428\n",
      "11.982285793823424\n",
      "11.982191348892714\n",
      "11.982096967384942\n",
      "11.982002649252774\n",
      "11.981908394448903\n",
      "11.981814202926083\n",
      "11.981720074637096\n",
      "11.981626009534748\n",
      "11.981532007571897\n",
      "11.981438068701424\n",
      "11.981344192876271\n",
      "11.981250380049401\n",
      "11.981156630173803\n",
      "11.98106294320253\n",
      "11.980969319088652\n",
      "11.980875757785284\n",
      "11.980782259245569\n",
      "11.980688823422708\n",
      "11.980595450269906\n"
     ]
    }
   ],
   "source": [
    "nn.fit(x_train, y_train, iteration=50, learning_rate=0.07)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = nn.predict(x_test)\n",
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      3514\n",
      "           1       0.82      1.00      0.90     16486\n",
      "\n",
      "    accuracy                           0.82     20000\n",
      "   macro avg       0.41      0.50      0.45     20000\n",
      "weighted avg       0.68      0.82      0.74     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\acer\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\acer\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "cr = classification_report(y_test, x)\n",
    "print(cr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}