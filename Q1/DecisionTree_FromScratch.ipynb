{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self):\n",
    "        ''' \n",
    "        Constructor for the Node class.\n",
    "        \n",
    "        Parameters:\n",
    "        feature_index (int): Index of the feature used for splitting at this node.\n",
    "        threshold (float): Threshold value for splitting at this node.\n",
    "        left (Node): Reference to the left child node.\n",
    "        right (Node): Reference to the right child node.\n",
    "        info_gain (float): Information gain from the split at this node.\n",
    "        value (varied): The class label if this is a leaf node.\n",
    "        '''        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier():\n",
    "    def __init__(self):\n",
    "       ''' \n",
    "        Constructor for the DecisionTreeClassifier class.\n",
    "        \n",
    "        Parameters:\n",
    "        min_samples_split (int): The minimum number of samples required to split a node.\n",
    "        max_depth (int): The maximum depth of the tree.\n",
    "        '''\n",
    "        \n",
    "    def build_tree(self):\n",
    "        ''' \n",
    "        Recursively builds the decision tree from the dataset.\n",
    "        \n",
    "        Parameters:\n",
    "        dataset (array): The data used to build the tree.\n",
    "        curr_depth (int): The current depth of the tree.\n",
    "        \n",
    "        Returns:\n",
    "        Node: The root node of the built tree.\n",
    "        '''\n",
    "        # TODO 1: split until stopping conditions are met      \n",
    "        # TODO 2: check if information gain is positive\n",
    "        # TODO 3: recur left\n",
    "        # TODO 4: recur right\n",
    "        # TODO 5: return decision node\n",
    "        # TODO 6: compute leaf node\n",
    "        # TODO 7: return leaft node\n",
    "        \n",
    "    def get_best_split(self):\n",
    "        '''\n",
    "        Finds the best split for the dataset.\n",
    "        \n",
    "        Parameters:\n",
    "        dataset (array): The dataset to split.\n",
    "        num_samples (int): Number of samples in the dataset.\n",
    "        num_features (int): Number of features in the dataset.\n",
    "        \n",
    "        Returns:\n",
    "        dict: Information about the best split.    \n",
    "        '''\n",
    "\n",
    "        # TODO 1: Define dictionary to store the best split   \n",
    "        # TODO 2: loop over all the features\n",
    "        # TODO 3: loop over all the feature values present in the data\n",
    "        # TODO 4: get current split\n",
    "        # TODO 5: check if childs are not null\n",
    "        # TODO 6: compute information gain\n",
    "        # TODO 7: update the best split if needed\n",
    "        # TODO 8: return best split\n",
    "        \n",
    "\n",
    "    \n",
    "    def split(self):\n",
    "        ''' \n",
    "        Splits the dataset based on the given feature index and threshold.\n",
    "        \n",
    "        Parameters:\n",
    "        dataset (array): The dataset to split.\n",
    "        feature_index (int): The index of the feature used for splitting.\n",
    "        threshold (float): The threshold value for splitting.\n",
    "        \n",
    "        Returns:\n",
    "        tuple: Two subsets of the dataset split by the threshold.\n",
    "        '''        \n",
    "\n",
    "    \n",
    "    def information_gain(self):\n",
    "        ''' \n",
    "        Computes the information gain of a split.\n",
    "        \n",
    "        Parameters:\n",
    "        parent (array): The parent dataset before the split.\n",
    "        l_child (array): The left child dataset after the split.\n",
    "        r_child (array): The right child dataset after the split.\n",
    "        mode (str): The criterion for information gain ('gini' or 'entropy').\n",
    "        \n",
    "        Returns:\n",
    "        float: The information gain of the split.\n",
    "        '''\n",
    "    \n",
    "    def entropy(self):\n",
    "        ''' \n",
    "        Computes the entropy of a dataset.\n",
    "        \n",
    "        Parameters:\n",
    "        y (array): The labels of the dataset.\n",
    "        \n",
    "        Returns:\n",
    "        float: The entropy of the dataset.\n",
    "        '''\n",
    "    \n",
    "    def gini_index(self, y):\n",
    "        ''' \n",
    "        Computes the Gini index of a dataset.\n",
    "        \n",
    "        Parameters:\n",
    "        y (array): The labels of the dataset.\n",
    "        \n",
    "        Returns:\n",
    "        float: The Gini index of the dataset.\n",
    "        '''\n",
    "        \n",
    "    def calculate_leaf_value(self):\n",
    "        ''' \n",
    "        Determines the value of a leaf node (most common class label).\n",
    "        \n",
    "        Parameters:\n",
    "        Y (array): The labels of the data in the leaf node.\n",
    "        \n",
    "        Returns:\n",
    "        varied: The most common class label in the leaf node.\n",
    "        '''\n",
    "    \n",
    "    def print_tree(self):\n",
    "        ''' \n",
    "        Prints the tree in a readable format.\n",
    "        \n",
    "        Parameters:\n",
    "        tree (Node, optional): The current node to print. If None, print from the root.\n",
    "        indent (str): The indentation string to format the tree structure.\n",
    "        '''\n",
    "    \n",
    "    def fit(self):\n",
    "        ''' \n",
    "        Trains the decision tree classifier.\n",
    "        \n",
    "        Parameters:\n",
    "        X (array): The features of the training data.\n",
    "        Y (array): The labels of the training data.\n",
    "        '''\n",
    "    \n",
    "    def predict(self):\n",
    "        ''' \n",
    "        Predicts class labels for a given set of features.\n",
    "        \n",
    "        Parameters:\n",
    "        X (array): The features of the data to predict.\n",
    "        \n",
    "        Returns:\n",
    "        list: Predicted class labels for each instance in X.\n",
    "        '''\n",
    "    \n",
    "    def make_prediction(self):\n",
    "        ''' \n",
    "        Predicts a class label for a single data point.\n",
    "        \n",
    "        Parameters:\n",
    "        x (array): The features of the single data point.\n",
    "        tree (Node): The current node in the tree during the recursive prediction.\n",
    "        \n",
    "        Returns:\n",
    "        varied: The predicted class label.\n",
    "        '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
