{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../../train.csv')\n",
    "test_data = pd.read_csv('../../test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set ->  False\n",
      "test set ->  False\n"
     ]
    }
   ],
   "source": [
    "#checking NAN values\n",
    "print('train set -> ', any(train_data.isnull().any()))\n",
    "print('test set -> ', any(test_data.isnull().any()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n0               0.33               0.00           0.67           0.0   \n1               0.00               0.00           0.00           0.0   \n2               0.08               0.08           0.76           0.0   \n3               0.05               0.05           0.40           0.0   \n4               0.00               0.00           0.84           0.0   \n...              ...                ...            ...           ...   \n3675            0.00               0.00           0.00           0.0   \n3676            0.00               0.00           0.66           0.0   \n3677            0.00               0.00           0.00           0.0   \n3678            0.00               0.00           0.00           0.0   \n3679            0.00               0.00           0.00           0.0   \n\n      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n0              0.22            0.00              0.00                0.00   \n1              0.00            0.00              0.00                0.00   \n2              0.85            1.02              0.25                0.17   \n3              0.34            0.00              0.00                0.00   \n4              0.56            0.00              0.00                0.56   \n...             ...             ...               ...                 ...   \n3675           0.00            0.00              0.00                0.00   \n3676           0.00            0.00              0.00                0.00   \n3677           0.00            0.00              0.00                0.00   \n3678           0.00            0.60              0.00                0.00   \n3679           0.00            0.00              0.00                0.00   \n\n      word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n0                0.44            0.11  ...        0.000        0.157   \n1                0.00            0.00  ...        0.000        0.000   \n2                0.59            0.08  ...        0.000        0.065   \n3                0.57            0.05  ...        0.019        0.099   \n4                0.00            0.00  ...        0.000        0.278   \n...               ...             ...  ...          ...          ...   \n3675             0.00            0.00  ...        0.000        0.000   \n3676             0.00            0.00  ...        0.000        0.104   \n3677             0.00            0.00  ...        0.208        0.671   \n3678             0.00            0.60  ...        0.094        0.000   \n3679             0.00            0.00  ...        0.000        0.000   \n\n      char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n0           0.000        0.392        0.176        0.078   \n1           0.000        0.145        0.291        0.000   \n2           0.000        0.403        0.117        0.013   \n3           0.000        0.099        0.079        0.009   \n4           0.000        0.046        0.000        0.000   \n...           ...          ...          ...          ...   \n3675        0.000        0.595        0.000        0.000   \n3676        0.209        0.104        0.000        0.000   \n3677        0.092        0.000        0.000        0.000   \n3678        0.000        0.094        0.189        0.000   \n3679        0.000        0.000        0.000        0.000   \n\n      capital_run_length_average  capital_run_length_longest  \\\n0                          2.606                          75   \n1                          2.500                          11   \n2                          7.484                         669   \n3                          4.881                          95   \n4                          1.661                           6   \n...                          ...                         ...   \n3675                       1.500                           4   \n3676                       2.152                          17   \n3677                       4.122                          20   \n3678                       1.976                          15   \n3679                       1.250                           2   \n\n      capital_run_length_total  Class  \n0                          391      1  \n1                           45      1  \n2                         1407      1  \n3                         1313      1  \n4                          118      1  \n...                        ...    ...  \n3675                        15      0  \n3676                       127      0  \n3677                       540      0  \n3678                        83      0  \n3679                         5      0  \n\n[3680 rows x 58 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word_freq_make</th>\n      <th>word_freq_address</th>\n      <th>word_freq_all</th>\n      <th>word_freq_3d</th>\n      <th>word_freq_our</th>\n      <th>word_freq_over</th>\n      <th>word_freq_remove</th>\n      <th>word_freq_internet</th>\n      <th>word_freq_order</th>\n      <th>word_freq_mail</th>\n      <th>...</th>\n      <th>char_freq_;</th>\n      <th>char_freq_(</th>\n      <th>char_freq_[</th>\n      <th>char_freq_!</th>\n      <th>char_freq_$</th>\n      <th>char_freq_#</th>\n      <th>capital_run_length_average</th>\n      <th>capital_run_length_longest</th>\n      <th>capital_run_length_total</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.33</td>\n      <td>0.00</td>\n      <td>0.67</td>\n      <td>0.0</td>\n      <td>0.22</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.44</td>\n      <td>0.11</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.157</td>\n      <td>0.000</td>\n      <td>0.392</td>\n      <td>0.176</td>\n      <td>0.078</td>\n      <td>2.606</td>\n      <td>75</td>\n      <td>391</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.145</td>\n      <td>0.291</td>\n      <td>0.000</td>\n      <td>2.500</td>\n      <td>11</td>\n      <td>45</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.08</td>\n      <td>0.08</td>\n      <td>0.76</td>\n      <td>0.0</td>\n      <td>0.85</td>\n      <td>1.02</td>\n      <td>0.25</td>\n      <td>0.17</td>\n      <td>0.59</td>\n      <td>0.08</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.065</td>\n      <td>0.000</td>\n      <td>0.403</td>\n      <td>0.117</td>\n      <td>0.013</td>\n      <td>7.484</td>\n      <td>669</td>\n      <td>1407</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.05</td>\n      <td>0.05</td>\n      <td>0.40</td>\n      <td>0.0</td>\n      <td>0.34</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.57</td>\n      <td>0.05</td>\n      <td>...</td>\n      <td>0.019</td>\n      <td>0.099</td>\n      <td>0.000</td>\n      <td>0.099</td>\n      <td>0.079</td>\n      <td>0.009</td>\n      <td>4.881</td>\n      <td>95</td>\n      <td>1313</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.84</td>\n      <td>0.0</td>\n      <td>0.56</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.56</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.278</td>\n      <td>0.000</td>\n      <td>0.046</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.661</td>\n      <td>6</td>\n      <td>118</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3675</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.595</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.500</td>\n      <td>4</td>\n      <td>15</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3676</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.66</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.104</td>\n      <td>0.209</td>\n      <td>0.104</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>2.152</td>\n      <td>17</td>\n      <td>127</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3677</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.208</td>\n      <td>0.671</td>\n      <td>0.092</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>4.122</td>\n      <td>20</td>\n      <td>540</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3678</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.60</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.60</td>\n      <td>...</td>\n      <td>0.094</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.094</td>\n      <td>0.189</td>\n      <td>0.000</td>\n      <td>1.976</td>\n      <td>15</td>\n      <td>83</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3679</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.250</td>\n      <td>2</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3680 rows × 58 columns</p>\n</div>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# splitting Data sets\n",
    "x_train = train_data.drop(columns='Class')\n",
    "y_train = train_data['Class']\n",
    "\n",
    "x_test = test_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n0               0.33               0.00           0.67           0.0   \n1               0.00               0.00           0.00           0.0   \n2               0.08               0.08           0.76           0.0   \n3               0.05               0.05           0.40           0.0   \n4               0.00               0.00           0.84           0.0   \n...              ...                ...            ...           ...   \n4455            0.00               0.00           0.57           0.0   \n4456            0.00               0.42           0.42           0.0   \n4457            0.31               0.20           0.72           0.0   \n4458            0.56               0.00           0.84           0.0   \n4459            0.00               0.18           1.10           0.0   \n\n      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n0              0.22            0.00              0.00                0.00   \n1              0.00            0.00              0.00                0.00   \n2              0.85            1.02              0.25                0.17   \n3              0.34            0.00              0.00                0.00   \n4              0.56            0.00              0.00                0.56   \n...             ...             ...               ...                 ...   \n4455           0.28            0.00              0.00                0.57   \n4456           0.00            0.00              0.00                0.00   \n4457           0.00            0.62              0.00                0.62   \n4458           0.28            0.84              0.00                0.84   \n4459           0.73            0.73              0.73                0.09   \n\n      word_freq_order  word_freq_mail  ...  word_freq_conference  char_freq_;  \\\n0                0.44            0.11  ...                   0.0        0.000   \n1                0.00            0.00  ...                   0.0        0.000   \n2                0.59            0.08  ...                   0.0        0.000   \n3                0.57            0.05  ...                   0.0        0.019   \n4                0.00            0.00  ...                   0.0        0.000   \n...               ...             ...  ...                   ...          ...   \n4455             0.00            0.00  ...                   0.0        0.000   \n4456             0.00            0.00  ...                   0.0        0.000   \n4457             0.62            0.93  ...                   0.0        0.000   \n4458             0.28            0.28  ...                   0.0        0.000   \n4459             0.83            0.27  ...                   0.0        0.000   \n\n      char_freq_(  char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n0           0.157          0.0        0.392        0.176        0.078   \n1           0.000          0.0        0.145        0.291        0.000   \n2           0.065          0.0        0.403        0.117        0.013   \n3           0.099          0.0        0.099        0.079        0.009   \n4           0.278          0.0        0.046        0.000        0.000   \n...           ...          ...          ...          ...          ...   \n4455        0.047          0.0        1.147        0.191        0.191   \n4456        0.075          0.0        0.600        0.300        0.000   \n4457        0.000          0.0        0.548        0.199        0.033   \n4458        0.128          0.0        1.289        0.042        0.000   \n4459        0.094          0.0        0.430        0.134        0.013   \n\n      capital_run_length_average  capital_run_length_longest  \\\n0                          2.606                          75   \n1                          2.500                          11   \n2                          7.484                         669   \n3                          4.881                          95   \n4                          1.661                           6   \n...                          ...                         ...   \n4455                      11.735                         489   \n4456                       4.020                          82   \n4457                      14.283                         685   \n4458                       3.979                          47   \n4459                       8.445                         696   \n\n      capital_run_length_total  \n0                          391  \n1                           45  \n2                         1407  \n3                         1313  \n4                          118  \n...                        ...  \n4455                       622  \n4456                       197  \n4457                      1514  \n4458                       386  \n4459                      1478  \n\n[4460 rows x 57 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word_freq_make</th>\n      <th>word_freq_address</th>\n      <th>word_freq_all</th>\n      <th>word_freq_3d</th>\n      <th>word_freq_our</th>\n      <th>word_freq_over</th>\n      <th>word_freq_remove</th>\n      <th>word_freq_internet</th>\n      <th>word_freq_order</th>\n      <th>word_freq_mail</th>\n      <th>...</th>\n      <th>word_freq_conference</th>\n      <th>char_freq_;</th>\n      <th>char_freq_(</th>\n      <th>char_freq_[</th>\n      <th>char_freq_!</th>\n      <th>char_freq_$</th>\n      <th>char_freq_#</th>\n      <th>capital_run_length_average</th>\n      <th>capital_run_length_longest</th>\n      <th>capital_run_length_total</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.33</td>\n      <td>0.00</td>\n      <td>0.67</td>\n      <td>0.0</td>\n      <td>0.22</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.44</td>\n      <td>0.11</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.157</td>\n      <td>0.0</td>\n      <td>0.392</td>\n      <td>0.176</td>\n      <td>0.078</td>\n      <td>2.606</td>\n      <td>75</td>\n      <td>391</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.145</td>\n      <td>0.291</td>\n      <td>0.000</td>\n      <td>2.500</td>\n      <td>11</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.08</td>\n      <td>0.08</td>\n      <td>0.76</td>\n      <td>0.0</td>\n      <td>0.85</td>\n      <td>1.02</td>\n      <td>0.25</td>\n      <td>0.17</td>\n      <td>0.59</td>\n      <td>0.08</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.065</td>\n      <td>0.0</td>\n      <td>0.403</td>\n      <td>0.117</td>\n      <td>0.013</td>\n      <td>7.484</td>\n      <td>669</td>\n      <td>1407</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.05</td>\n      <td>0.05</td>\n      <td>0.40</td>\n      <td>0.0</td>\n      <td>0.34</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.57</td>\n      <td>0.05</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.019</td>\n      <td>0.099</td>\n      <td>0.0</td>\n      <td>0.099</td>\n      <td>0.079</td>\n      <td>0.009</td>\n      <td>4.881</td>\n      <td>95</td>\n      <td>1313</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.84</td>\n      <td>0.0</td>\n      <td>0.56</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.56</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.278</td>\n      <td>0.0</td>\n      <td>0.046</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.661</td>\n      <td>6</td>\n      <td>118</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4455</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.57</td>\n      <td>0.0</td>\n      <td>0.28</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.57</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.047</td>\n      <td>0.0</td>\n      <td>1.147</td>\n      <td>0.191</td>\n      <td>0.191</td>\n      <td>11.735</td>\n      <td>489</td>\n      <td>622</td>\n    </tr>\n    <tr>\n      <th>4456</th>\n      <td>0.00</td>\n      <td>0.42</td>\n      <td>0.42</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.075</td>\n      <td>0.0</td>\n      <td>0.600</td>\n      <td>0.300</td>\n      <td>0.000</td>\n      <td>4.020</td>\n      <td>82</td>\n      <td>197</td>\n    </tr>\n    <tr>\n      <th>4457</th>\n      <td>0.31</td>\n      <td>0.20</td>\n      <td>0.72</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.62</td>\n      <td>0.00</td>\n      <td>0.62</td>\n      <td>0.62</td>\n      <td>0.93</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.548</td>\n      <td>0.199</td>\n      <td>0.033</td>\n      <td>14.283</td>\n      <td>685</td>\n      <td>1514</td>\n    </tr>\n    <tr>\n      <th>4458</th>\n      <td>0.56</td>\n      <td>0.00</td>\n      <td>0.84</td>\n      <td>0.0</td>\n      <td>0.28</td>\n      <td>0.84</td>\n      <td>0.00</td>\n      <td>0.84</td>\n      <td>0.28</td>\n      <td>0.28</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.128</td>\n      <td>0.0</td>\n      <td>1.289</td>\n      <td>0.042</td>\n      <td>0.000</td>\n      <td>3.979</td>\n      <td>47</td>\n      <td>386</td>\n    </tr>\n    <tr>\n      <th>4459</th>\n      <td>0.00</td>\n      <td>0.18</td>\n      <td>1.10</td>\n      <td>0.0</td>\n      <td>0.73</td>\n      <td>0.73</td>\n      <td>0.73</td>\n      <td>0.09</td>\n      <td>0.83</td>\n      <td>0.27</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.094</td>\n      <td>0.0</td>\n      <td>0.430</td>\n      <td>0.134</td>\n      <td>0.013</td>\n      <td>8.445</td>\n      <td>696</td>\n      <td>1478</td>\n    </tr>\n  </tbody>\n</table>\n<p>4460 rows × 57 columns</p>\n</div>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Oversampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42, sampling_strategy='minority')\n",
    "x_resample_over, y_resample_over = ros.fit_resample(x_train, y_train)\n",
    "x_resample_over"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": "LogisticRegression(max_iter=500)",
      "text/html": "<style>#sk-container-id-11 {color: black;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=500)</pre></div></div></div></div></div>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression with Oversampling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_reg = LogisticRegression(max_iter=500)\n",
    "lr_reg.fit(x_resample_over, y_resample_over)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "              Value\nAccuracy   0.934081\nRecall     0.924664\nPrecision  0.942413\nF1-score   0.933454",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Accuracy</th>\n      <td>0.934081</td>\n    </tr>\n    <tr>\n      <th>Recall</th>\n      <td>0.924664</td>\n    </tr>\n    <tr>\n      <th>Precision</th>\n      <td>0.942413</td>\n    </tr>\n    <tr>\n      <th>F1-score</th>\n      <td>0.933454</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluation of training set for Oversampling\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
    "y_resample_over_pred = lr_reg.predict(x_resample_over)\n",
    "\n",
    "accuracy = accuracy_score(y_resample_over, y_resample_over_pred)\n",
    "recall = recall_score(y_resample_over, y_resample_over_pred)\n",
    "precision = precision_score(y_resample_over, y_resample_over_pred)\n",
    "f1_score = f1_score(y_resample_over, y_resample_over_pred)\n",
    "\n",
    "errors = pd.DataFrame({'Value': [accuracy, recall, precision, f1_score]}, index=['Accuracy', 'Recall', 'Precision', 'F1-score'])\n",
    "errors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confusion_matrix for oversampling\n",
    "cm = confusion_matrix(y_resample_over, y_resample_over_pred)\n",
    "sns.heatmap(cm/np.sum(cm), annot=True,\n",
    "            fmt='.2%', cmap='Blues')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n1506            1.04               0.00           0.52           0.0   \n2031            0.00               0.00           0.00           0.0   \n2209            0.00               0.00           0.00           0.0   \n2698            0.00               0.00           0.38           0.0   \n3391            0.00               0.00           0.00           0.0   \n...              ...                ...            ...           ...   \n1445            0.00               0.00           0.73           0.0   \n1446            0.26               0.72           0.85           0.0   \n1447            0.00               0.47           0.00           0.0   \n1448            0.00               0.00           0.00           0.0   \n1449            0.54               0.13           0.38           0.0   \n\n      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n1506           0.52            0.00              0.00                0.00   \n2031           0.00            0.00              0.00                0.00   \n2209           0.00            0.00              0.00                0.00   \n2698           0.38            0.38              0.00                0.00   \n3391           0.00            0.00              0.00                0.00   \n...             ...             ...               ...                 ...   \n1445           0.36            0.00              0.00                0.00   \n1446           0.00            0.19              0.06                0.33   \n1447           0.94            0.00              0.94                0.00   \n1448           0.00            0.00              1.96                0.00   \n1449           0.05            0.19              0.00                0.05   \n\n      word_freq_order  word_freq_mail  ...  word_freq_conference  char_freq_;  \\\n1506             0.00            0.00  ...                   0.0        0.000   \n2031             0.00            0.00  ...                   0.0        0.101   \n2209             0.00            0.00  ...                   0.0        0.000   \n2698             0.38            0.00  ...                   0.0        0.000   \n3391             0.00            0.00  ...                   0.0        0.000   \n...               ...             ...  ...                   ...          ...   \n1445             0.00            0.00  ...                   0.0        0.000   \n1446             0.72            0.46  ...                   0.0        0.000   \n1447             0.00            0.00  ...                   0.0        0.000   \n1448             0.00            0.00  ...                   0.0        0.163   \n1449             0.35            0.16  ...                   0.0        0.000   \n\n      char_freq_(  char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n1506        0.309        0.000        0.309        0.000        0.000   \n2031        0.254        0.101        0.050        0.050        0.000   \n2209        0.000        0.000        0.000        0.000        0.000   \n2698        0.061        0.000        0.000        0.000        0.000   \n3391        0.000        0.000        0.000        0.000        0.000   \n...           ...          ...          ...          ...          ...   \n1445        0.000        0.000        0.604        0.181        0.000   \n1446        0.131        0.000        0.101        0.101        0.202   \n1447        0.074        0.074        0.000        0.000        0.000   \n1448        0.489        0.000        0.326        0.000        0.000   \n1449        0.086        0.000        0.273        0.150        0.159   \n\n      capital_run_length_average  capital_run_length_longest  \\\n1506                       3.973                          34   \n2031                       2.725                          15   \n2209                       3.888                           8   \n2698                       2.953                          34   \n3391                       2.333                           5   \n...                          ...                         ...   \n1445                       3.787                          58   \n1446                       4.398                          79   \n1447                       2.125                          11   \n1448                       2.300                          12   \n1449                       6.789                         195   \n\n      capital_run_length_total  \n1506                       151  \n2031                       248  \n2209                        35  \n2698                       127  \n3391                         7  \n...                        ...  \n1445                       356  \n1446                      1280  \n1447                       102  \n1448                        46  \n1449                      3327  \n\n[2900 rows x 57 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word_freq_make</th>\n      <th>word_freq_address</th>\n      <th>word_freq_all</th>\n      <th>word_freq_3d</th>\n      <th>word_freq_our</th>\n      <th>word_freq_over</th>\n      <th>word_freq_remove</th>\n      <th>word_freq_internet</th>\n      <th>word_freq_order</th>\n      <th>word_freq_mail</th>\n      <th>...</th>\n      <th>word_freq_conference</th>\n      <th>char_freq_;</th>\n      <th>char_freq_(</th>\n      <th>char_freq_[</th>\n      <th>char_freq_!</th>\n      <th>char_freq_$</th>\n      <th>char_freq_#</th>\n      <th>capital_run_length_average</th>\n      <th>capital_run_length_longest</th>\n      <th>capital_run_length_total</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1506</th>\n      <td>1.04</td>\n      <td>0.00</td>\n      <td>0.52</td>\n      <td>0.0</td>\n      <td>0.52</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.309</td>\n      <td>0.000</td>\n      <td>0.309</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.973</td>\n      <td>34</td>\n      <td>151</td>\n    </tr>\n    <tr>\n      <th>2031</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.101</td>\n      <td>0.254</td>\n      <td>0.101</td>\n      <td>0.050</td>\n      <td>0.050</td>\n      <td>0.000</td>\n      <td>2.725</td>\n      <td>15</td>\n      <td>248</td>\n    </tr>\n    <tr>\n      <th>2209</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.888</td>\n      <td>8</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>2698</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.38</td>\n      <td>0.0</td>\n      <td>0.38</td>\n      <td>0.38</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.38</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.061</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>2.953</td>\n      <td>34</td>\n      <td>127</td>\n    </tr>\n    <tr>\n      <th>3391</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>2.333</td>\n      <td>5</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1445</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.73</td>\n      <td>0.0</td>\n      <td>0.36</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.604</td>\n      <td>0.181</td>\n      <td>0.000</td>\n      <td>3.787</td>\n      <td>58</td>\n      <td>356</td>\n    </tr>\n    <tr>\n      <th>1446</th>\n      <td>0.26</td>\n      <td>0.72</td>\n      <td>0.85</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.19</td>\n      <td>0.06</td>\n      <td>0.33</td>\n      <td>0.72</td>\n      <td>0.46</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.131</td>\n      <td>0.000</td>\n      <td>0.101</td>\n      <td>0.101</td>\n      <td>0.202</td>\n      <td>4.398</td>\n      <td>79</td>\n      <td>1280</td>\n    </tr>\n    <tr>\n      <th>1447</th>\n      <td>0.00</td>\n      <td>0.47</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.94</td>\n      <td>0.00</td>\n      <td>0.94</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.074</td>\n      <td>0.074</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>2.125</td>\n      <td>11</td>\n      <td>102</td>\n    </tr>\n    <tr>\n      <th>1448</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.96</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.163</td>\n      <td>0.489</td>\n      <td>0.000</td>\n      <td>0.326</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>2.300</td>\n      <td>12</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>1449</th>\n      <td>0.54</td>\n      <td>0.13</td>\n      <td>0.38</td>\n      <td>0.0</td>\n      <td>0.05</td>\n      <td>0.19</td>\n      <td>0.00</td>\n      <td>0.05</td>\n      <td>0.35</td>\n      <td>0.16</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.086</td>\n      <td>0.000</td>\n      <td>0.273</td>\n      <td>0.150</td>\n      <td>0.159</td>\n      <td>6.789</td>\n      <td>195</td>\n      <td>3327</td>\n    </tr>\n  </tbody>\n</table>\n<p>2900 rows × 57 columns</p>\n</div>"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Undersampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "ros = RandomUnderSampler(random_state=42, sampling_strategy='majority')\n",
    "x_resample_under, y_resample_under = ros.fit_resample(x_train, y_train)\n",
    "x_resample_under"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": "LogisticRegression(max_iter=500)",
      "text/html": "<style>#sk-container-id-12 {color: black;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=500)</pre></div></div></div></div></div>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression with Oversampling\n",
    "\n",
    "lr_reg = LogisticRegression(max_iter=500)\n",
    "lr_reg.fit(x_resample_under, y_resample_under)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "              Value\nAccuracy   0.931034\nRecall     0.922069\nPrecision  0.938904\nF1-score   0.930411",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Accuracy</th>\n      <td>0.931034</td>\n    </tr>\n    <tr>\n      <th>Recall</th>\n      <td>0.922069</td>\n    </tr>\n    <tr>\n      <th>Precision</th>\n      <td>0.938904</td>\n    </tr>\n    <tr>\n      <th>F1-score</th>\n      <td>0.930411</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluation of training set for Undersampling\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
    "y_resample_under_pred = lr_reg.predict(x_resample_under)\n",
    "\n",
    "accuracy = accuracy_score(y_resample_under, y_resample_under_pred)\n",
    "recall = recall_score(y_resample_under, y_resample_under_pred)\n",
    "precision = precision_score(y_resample_under, y_resample_under_pred)\n",
    "f1_score = f1_score(y_resample_under, y_resample_under_pred)\n",
    "\n",
    "errors = pd.DataFrame({'Value': [accuracy, recall, precision, f1_score]}, index=['Accuracy', 'Recall', 'Precision', 'F1-score'])\n",
    "errors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression(class_weight='balanced', solver='newton-cg')",
      "text/html": "<style>#sk-container-id-13 {color: black;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, solver=&#x27;newton-cg&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, solver=&#x27;newton-cg&#x27;)</pre></div></div></div></div></div>"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression with weighted Loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_reg = LogisticRegression(solver='newton-cg', class_weight='balanced')\n",
    "lr_reg.fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "              Value\nAccuracy   0.935598\nRecall     0.926207\nPrecision  0.911745\nF1-score   0.918919",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Accuracy</th>\n      <td>0.935598</td>\n    </tr>\n    <tr>\n      <th>Recall</th>\n      <td>0.926207</td>\n    </tr>\n    <tr>\n      <th>Precision</th>\n      <td>0.911745</td>\n    </tr>\n    <tr>\n      <th>F1-score</th>\n      <td>0.918919</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluation of training set for weighted loss\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
    "y_weighted_pred = lr_reg.predict(x_train)\n",
    "\n",
    "accuracy = accuracy_score(y_train, y_weighted_pred)\n",
    "recall = recall_score(y_train, y_weighted_pred)\n",
    "precision = precision_score(y_train, y_weighted_pred)\n",
    "f1_score = f1_score(y_train, y_weighted_pred)\n",
    "\n",
    "errors = pd.DataFrame({'Value': [accuracy, recall, precision, f1_score]}, index=['Accuracy', 'Recall', 'Precision', 'F1-score'])\n",
    "errors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}