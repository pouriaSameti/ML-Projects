{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../../train.csv')\n",
    "test_data = pd.read_csv('../../test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set ->  False\n",
      "test set ->  False\n"
     ]
    }
   ],
   "source": [
    "#checking NAN values\n",
    "print('train set -> ', any(train_data.isnull().any()))\n",
    "print('test set -> ', any(test_data.isnull().any()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n0               0.33               0.00           0.67           0.0   \n1               0.00               0.00           0.00           0.0   \n2               0.08               0.08           0.76           0.0   \n3               0.05               0.05           0.40           0.0   \n4               0.00               0.00           0.84           0.0   \n...              ...                ...            ...           ...   \n3675            0.00               0.00           0.00           0.0   \n3676            0.00               0.00           0.66           0.0   \n3677            0.00               0.00           0.00           0.0   \n3678            0.00               0.00           0.00           0.0   \n3679            0.00               0.00           0.00           0.0   \n\n      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n0              0.22            0.00              0.00                0.00   \n1              0.00            0.00              0.00                0.00   \n2              0.85            1.02              0.25                0.17   \n3              0.34            0.00              0.00                0.00   \n4              0.56            0.00              0.00                0.56   \n...             ...             ...               ...                 ...   \n3675           0.00            0.00              0.00                0.00   \n3676           0.00            0.00              0.00                0.00   \n3677           0.00            0.00              0.00                0.00   \n3678           0.00            0.60              0.00                0.00   \n3679           0.00            0.00              0.00                0.00   \n\n      word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n0                0.44            0.11  ...        0.000        0.157   \n1                0.00            0.00  ...        0.000        0.000   \n2                0.59            0.08  ...        0.000        0.065   \n3                0.57            0.05  ...        0.019        0.099   \n4                0.00            0.00  ...        0.000        0.278   \n...               ...             ...  ...          ...          ...   \n3675             0.00            0.00  ...        0.000        0.000   \n3676             0.00            0.00  ...        0.000        0.104   \n3677             0.00            0.00  ...        0.208        0.671   \n3678             0.00            0.60  ...        0.094        0.000   \n3679             0.00            0.00  ...        0.000        0.000   \n\n      char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n0           0.000        0.392        0.176        0.078   \n1           0.000        0.145        0.291        0.000   \n2           0.000        0.403        0.117        0.013   \n3           0.000        0.099        0.079        0.009   \n4           0.000        0.046        0.000        0.000   \n...           ...          ...          ...          ...   \n3675        0.000        0.595        0.000        0.000   \n3676        0.209        0.104        0.000        0.000   \n3677        0.092        0.000        0.000        0.000   \n3678        0.000        0.094        0.189        0.000   \n3679        0.000        0.000        0.000        0.000   \n\n      capital_run_length_average  capital_run_length_longest  \\\n0                          2.606                          75   \n1                          2.500                          11   \n2                          7.484                         669   \n3                          4.881                          95   \n4                          1.661                           6   \n...                          ...                         ...   \n3675                       1.500                           4   \n3676                       2.152                          17   \n3677                       4.122                          20   \n3678                       1.976                          15   \n3679                       1.250                           2   \n\n      capital_run_length_total  Class  \n0                          391      1  \n1                           45      1  \n2                         1407      1  \n3                         1313      1  \n4                          118      1  \n...                        ...    ...  \n3675                        15      0  \n3676                       127      0  \n3677                       540      0  \n3678                        83      0  \n3679                         5      0  \n\n[3680 rows x 58 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word_freq_make</th>\n      <th>word_freq_address</th>\n      <th>word_freq_all</th>\n      <th>word_freq_3d</th>\n      <th>word_freq_our</th>\n      <th>word_freq_over</th>\n      <th>word_freq_remove</th>\n      <th>word_freq_internet</th>\n      <th>word_freq_order</th>\n      <th>word_freq_mail</th>\n      <th>...</th>\n      <th>char_freq_;</th>\n      <th>char_freq_(</th>\n      <th>char_freq_[</th>\n      <th>char_freq_!</th>\n      <th>char_freq_$</th>\n      <th>char_freq_#</th>\n      <th>capital_run_length_average</th>\n      <th>capital_run_length_longest</th>\n      <th>capital_run_length_total</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.33</td>\n      <td>0.00</td>\n      <td>0.67</td>\n      <td>0.0</td>\n      <td>0.22</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.44</td>\n      <td>0.11</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.157</td>\n      <td>0.000</td>\n      <td>0.392</td>\n      <td>0.176</td>\n      <td>0.078</td>\n      <td>2.606</td>\n      <td>75</td>\n      <td>391</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.145</td>\n      <td>0.291</td>\n      <td>0.000</td>\n      <td>2.500</td>\n      <td>11</td>\n      <td>45</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.08</td>\n      <td>0.08</td>\n      <td>0.76</td>\n      <td>0.0</td>\n      <td>0.85</td>\n      <td>1.02</td>\n      <td>0.25</td>\n      <td>0.17</td>\n      <td>0.59</td>\n      <td>0.08</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.065</td>\n      <td>0.000</td>\n      <td>0.403</td>\n      <td>0.117</td>\n      <td>0.013</td>\n      <td>7.484</td>\n      <td>669</td>\n      <td>1407</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.05</td>\n      <td>0.05</td>\n      <td>0.40</td>\n      <td>0.0</td>\n      <td>0.34</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.57</td>\n      <td>0.05</td>\n      <td>...</td>\n      <td>0.019</td>\n      <td>0.099</td>\n      <td>0.000</td>\n      <td>0.099</td>\n      <td>0.079</td>\n      <td>0.009</td>\n      <td>4.881</td>\n      <td>95</td>\n      <td>1313</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.84</td>\n      <td>0.0</td>\n      <td>0.56</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.56</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.278</td>\n      <td>0.000</td>\n      <td>0.046</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.661</td>\n      <td>6</td>\n      <td>118</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3675</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.595</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.500</td>\n      <td>4</td>\n      <td>15</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3676</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.66</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.104</td>\n      <td>0.209</td>\n      <td>0.104</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>2.152</td>\n      <td>17</td>\n      <td>127</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3677</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.208</td>\n      <td>0.671</td>\n      <td>0.092</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>4.122</td>\n      <td>20</td>\n      <td>540</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3678</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.60</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.60</td>\n      <td>...</td>\n      <td>0.094</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.094</td>\n      <td>0.189</td>\n      <td>0.000</td>\n      <td>1.976</td>\n      <td>15</td>\n      <td>83</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3679</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.250</td>\n      <td>2</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3680 rows × 58 columns</p>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# splitting Data sets\n",
    "x_train = train_data.drop(columns='Class')\n",
    "y_train = train_data['Class']\n",
    "\n",
    "x_test = test_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n0               0.33               0.00           0.67           0.0   \n1               0.00               0.00           0.00           0.0   \n2               0.08               0.08           0.76           0.0   \n3               0.05               0.05           0.40           0.0   \n4               0.00               0.00           0.84           0.0   \n...              ...                ...            ...           ...   \n4455            0.00               0.00           0.57           0.0   \n4456            0.00               0.42           0.42           0.0   \n4457            0.31               0.20           0.72           0.0   \n4458            0.56               0.00           0.84           0.0   \n4459            0.00               0.18           1.10           0.0   \n\n      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n0              0.22            0.00              0.00                0.00   \n1              0.00            0.00              0.00                0.00   \n2              0.85            1.02              0.25                0.17   \n3              0.34            0.00              0.00                0.00   \n4              0.56            0.00              0.00                0.56   \n...             ...             ...               ...                 ...   \n4455           0.28            0.00              0.00                0.57   \n4456           0.00            0.00              0.00                0.00   \n4457           0.00            0.62              0.00                0.62   \n4458           0.28            0.84              0.00                0.84   \n4459           0.73            0.73              0.73                0.09   \n\n      word_freq_order  word_freq_mail  ...  word_freq_conference  char_freq_;  \\\n0                0.44            0.11  ...                   0.0        0.000   \n1                0.00            0.00  ...                   0.0        0.000   \n2                0.59            0.08  ...                   0.0        0.000   \n3                0.57            0.05  ...                   0.0        0.019   \n4                0.00            0.00  ...                   0.0        0.000   \n...               ...             ...  ...                   ...          ...   \n4455             0.00            0.00  ...                   0.0        0.000   \n4456             0.00            0.00  ...                   0.0        0.000   \n4457             0.62            0.93  ...                   0.0        0.000   \n4458             0.28            0.28  ...                   0.0        0.000   \n4459             0.83            0.27  ...                   0.0        0.000   \n\n      char_freq_(  char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n0           0.157          0.0        0.392        0.176        0.078   \n1           0.000          0.0        0.145        0.291        0.000   \n2           0.065          0.0        0.403        0.117        0.013   \n3           0.099          0.0        0.099        0.079        0.009   \n4           0.278          0.0        0.046        0.000        0.000   \n...           ...          ...          ...          ...          ...   \n4455        0.047          0.0        1.147        0.191        0.191   \n4456        0.075          0.0        0.600        0.300        0.000   \n4457        0.000          0.0        0.548        0.199        0.033   \n4458        0.128          0.0        1.289        0.042        0.000   \n4459        0.094          0.0        0.430        0.134        0.013   \n\n      capital_run_length_average  capital_run_length_longest  \\\n0                          2.606                          75   \n1                          2.500                          11   \n2                          7.484                         669   \n3                          4.881                          95   \n4                          1.661                           6   \n...                          ...                         ...   \n4455                      11.735                         489   \n4456                       4.020                          82   \n4457                      14.283                         685   \n4458                       3.979                          47   \n4459                       8.445                         696   \n\n      capital_run_length_total  \n0                          391  \n1                           45  \n2                         1407  \n3                         1313  \n4                          118  \n...                        ...  \n4455                       622  \n4456                       197  \n4457                      1514  \n4458                       386  \n4459                      1478  \n\n[4460 rows x 57 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word_freq_make</th>\n      <th>word_freq_address</th>\n      <th>word_freq_all</th>\n      <th>word_freq_3d</th>\n      <th>word_freq_our</th>\n      <th>word_freq_over</th>\n      <th>word_freq_remove</th>\n      <th>word_freq_internet</th>\n      <th>word_freq_order</th>\n      <th>word_freq_mail</th>\n      <th>...</th>\n      <th>word_freq_conference</th>\n      <th>char_freq_;</th>\n      <th>char_freq_(</th>\n      <th>char_freq_[</th>\n      <th>char_freq_!</th>\n      <th>char_freq_$</th>\n      <th>char_freq_#</th>\n      <th>capital_run_length_average</th>\n      <th>capital_run_length_longest</th>\n      <th>capital_run_length_total</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.33</td>\n      <td>0.00</td>\n      <td>0.67</td>\n      <td>0.0</td>\n      <td>0.22</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.44</td>\n      <td>0.11</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.157</td>\n      <td>0.0</td>\n      <td>0.392</td>\n      <td>0.176</td>\n      <td>0.078</td>\n      <td>2.606</td>\n      <td>75</td>\n      <td>391</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.145</td>\n      <td>0.291</td>\n      <td>0.000</td>\n      <td>2.500</td>\n      <td>11</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.08</td>\n      <td>0.08</td>\n      <td>0.76</td>\n      <td>0.0</td>\n      <td>0.85</td>\n      <td>1.02</td>\n      <td>0.25</td>\n      <td>0.17</td>\n      <td>0.59</td>\n      <td>0.08</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.065</td>\n      <td>0.0</td>\n      <td>0.403</td>\n      <td>0.117</td>\n      <td>0.013</td>\n      <td>7.484</td>\n      <td>669</td>\n      <td>1407</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.05</td>\n      <td>0.05</td>\n      <td>0.40</td>\n      <td>0.0</td>\n      <td>0.34</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.57</td>\n      <td>0.05</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.019</td>\n      <td>0.099</td>\n      <td>0.0</td>\n      <td>0.099</td>\n      <td>0.079</td>\n      <td>0.009</td>\n      <td>4.881</td>\n      <td>95</td>\n      <td>1313</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.84</td>\n      <td>0.0</td>\n      <td>0.56</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.56</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.278</td>\n      <td>0.0</td>\n      <td>0.046</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.661</td>\n      <td>6</td>\n      <td>118</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4455</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.57</td>\n      <td>0.0</td>\n      <td>0.28</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.57</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.047</td>\n      <td>0.0</td>\n      <td>1.147</td>\n      <td>0.191</td>\n      <td>0.191</td>\n      <td>11.735</td>\n      <td>489</td>\n      <td>622</td>\n    </tr>\n    <tr>\n      <th>4456</th>\n      <td>0.00</td>\n      <td>0.42</td>\n      <td>0.42</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.075</td>\n      <td>0.0</td>\n      <td>0.600</td>\n      <td>0.300</td>\n      <td>0.000</td>\n      <td>4.020</td>\n      <td>82</td>\n      <td>197</td>\n    </tr>\n    <tr>\n      <th>4457</th>\n      <td>0.31</td>\n      <td>0.20</td>\n      <td>0.72</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.62</td>\n      <td>0.00</td>\n      <td>0.62</td>\n      <td>0.62</td>\n      <td>0.93</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.548</td>\n      <td>0.199</td>\n      <td>0.033</td>\n      <td>14.283</td>\n      <td>685</td>\n      <td>1514</td>\n    </tr>\n    <tr>\n      <th>4458</th>\n      <td>0.56</td>\n      <td>0.00</td>\n      <td>0.84</td>\n      <td>0.0</td>\n      <td>0.28</td>\n      <td>0.84</td>\n      <td>0.00</td>\n      <td>0.84</td>\n      <td>0.28</td>\n      <td>0.28</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.128</td>\n      <td>0.0</td>\n      <td>1.289</td>\n      <td>0.042</td>\n      <td>0.000</td>\n      <td>3.979</td>\n      <td>47</td>\n      <td>386</td>\n    </tr>\n    <tr>\n      <th>4459</th>\n      <td>0.00</td>\n      <td>0.18</td>\n      <td>1.10</td>\n      <td>0.0</td>\n      <td>0.73</td>\n      <td>0.73</td>\n      <td>0.73</td>\n      <td>0.09</td>\n      <td>0.83</td>\n      <td>0.27</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.094</td>\n      <td>0.0</td>\n      <td>0.430</td>\n      <td>0.134</td>\n      <td>0.013</td>\n      <td>8.445</td>\n      <td>696</td>\n      <td>1478</td>\n    </tr>\n  </tbody>\n</table>\n<p>4460 rows × 57 columns</p>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Oversampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42, sampling_strategy='minority')\n",
    "x_resample_over, y_resample_over = ros.fit_resample(x_train, y_train)\n",
    "x_resample_over"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": "LogisticRegression(max_iter=500)",
      "text/html": "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=500)</pre></div></div></div></div></div>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression with Oversampling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_reg = LogisticRegression(max_iter=500)\n",
    "lr_reg.fit(x_resample_over, y_resample_over)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "              Value\nAccuracy   0.934081\nRecall     0.924664\nPrecision  0.942413\nF1-score   0.933454",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Accuracy</th>\n      <td>0.934081</td>\n    </tr>\n    <tr>\n      <th>Recall</th>\n      <td>0.924664</td>\n    </tr>\n    <tr>\n      <th>Precision</th>\n      <td>0.942413</td>\n    </tr>\n    <tr>\n      <th>F1-score</th>\n      <td>0.933454</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluation of training set for Oversampling\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
    "y_resample_over_pred = lr_reg.predict(x_resample_over)\n",
    "\n",
    "accuracy = accuracy_score(y_resample_over, y_resample_over_pred)\n",
    "recall = recall_score(y_resample_over, y_resample_over_pred)\n",
    "precision = precision_score(y_resample_over, y_resample_over_pred)\n",
    "f1_score = f1_score(y_resample_over, y_resample_over_pred)\n",
    "\n",
    "errors = pd.DataFrame({'Value': [accuracy, recall, precision, f1_score]}, index=['Accuracy', 'Recall', 'Precision', 'F1-score'])\n",
    "errors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n1506            1.04               0.00           0.52           0.0   \n2031            0.00               0.00           0.00           0.0   \n2209            0.00               0.00           0.00           0.0   \n2698            0.00               0.00           0.38           0.0   \n3391            0.00               0.00           0.00           0.0   \n...              ...                ...            ...           ...   \n1445            0.00               0.00           0.73           0.0   \n1446            0.26               0.72           0.85           0.0   \n1447            0.00               0.47           0.00           0.0   \n1448            0.00               0.00           0.00           0.0   \n1449            0.54               0.13           0.38           0.0   \n\n      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n1506           0.52            0.00              0.00                0.00   \n2031           0.00            0.00              0.00                0.00   \n2209           0.00            0.00              0.00                0.00   \n2698           0.38            0.38              0.00                0.00   \n3391           0.00            0.00              0.00                0.00   \n...             ...             ...               ...                 ...   \n1445           0.36            0.00              0.00                0.00   \n1446           0.00            0.19              0.06                0.33   \n1447           0.94            0.00              0.94                0.00   \n1448           0.00            0.00              1.96                0.00   \n1449           0.05            0.19              0.00                0.05   \n\n      word_freq_order  word_freq_mail  ...  word_freq_conference  char_freq_;  \\\n1506             0.00            0.00  ...                   0.0        0.000   \n2031             0.00            0.00  ...                   0.0        0.101   \n2209             0.00            0.00  ...                   0.0        0.000   \n2698             0.38            0.00  ...                   0.0        0.000   \n3391             0.00            0.00  ...                   0.0        0.000   \n...               ...             ...  ...                   ...          ...   \n1445             0.00            0.00  ...                   0.0        0.000   \n1446             0.72            0.46  ...                   0.0        0.000   \n1447             0.00            0.00  ...                   0.0        0.000   \n1448             0.00            0.00  ...                   0.0        0.163   \n1449             0.35            0.16  ...                   0.0        0.000   \n\n      char_freq_(  char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n1506        0.309        0.000        0.309        0.000        0.000   \n2031        0.254        0.101        0.050        0.050        0.000   \n2209        0.000        0.000        0.000        0.000        0.000   \n2698        0.061        0.000        0.000        0.000        0.000   \n3391        0.000        0.000        0.000        0.000        0.000   \n...           ...          ...          ...          ...          ...   \n1445        0.000        0.000        0.604        0.181        0.000   \n1446        0.131        0.000        0.101        0.101        0.202   \n1447        0.074        0.074        0.000        0.000        0.000   \n1448        0.489        0.000        0.326        0.000        0.000   \n1449        0.086        0.000        0.273        0.150        0.159   \n\n      capital_run_length_average  capital_run_length_longest  \\\n1506                       3.973                          34   \n2031                       2.725                          15   \n2209                       3.888                           8   \n2698                       2.953                          34   \n3391                       2.333                           5   \n...                          ...                         ...   \n1445                       3.787                          58   \n1446                       4.398                          79   \n1447                       2.125                          11   \n1448                       2.300                          12   \n1449                       6.789                         195   \n\n      capital_run_length_total  \n1506                       151  \n2031                       248  \n2209                        35  \n2698                       127  \n3391                         7  \n...                        ...  \n1445                       356  \n1446                      1280  \n1447                       102  \n1448                        46  \n1449                      3327  \n\n[2900 rows x 57 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word_freq_make</th>\n      <th>word_freq_address</th>\n      <th>word_freq_all</th>\n      <th>word_freq_3d</th>\n      <th>word_freq_our</th>\n      <th>word_freq_over</th>\n      <th>word_freq_remove</th>\n      <th>word_freq_internet</th>\n      <th>word_freq_order</th>\n      <th>word_freq_mail</th>\n      <th>...</th>\n      <th>word_freq_conference</th>\n      <th>char_freq_;</th>\n      <th>char_freq_(</th>\n      <th>char_freq_[</th>\n      <th>char_freq_!</th>\n      <th>char_freq_$</th>\n      <th>char_freq_#</th>\n      <th>capital_run_length_average</th>\n      <th>capital_run_length_longest</th>\n      <th>capital_run_length_total</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1506</th>\n      <td>1.04</td>\n      <td>0.00</td>\n      <td>0.52</td>\n      <td>0.0</td>\n      <td>0.52</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.309</td>\n      <td>0.000</td>\n      <td>0.309</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.973</td>\n      <td>34</td>\n      <td>151</td>\n    </tr>\n    <tr>\n      <th>2031</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.101</td>\n      <td>0.254</td>\n      <td>0.101</td>\n      <td>0.050</td>\n      <td>0.050</td>\n      <td>0.000</td>\n      <td>2.725</td>\n      <td>15</td>\n      <td>248</td>\n    </tr>\n    <tr>\n      <th>2209</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.888</td>\n      <td>8</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>2698</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.38</td>\n      <td>0.0</td>\n      <td>0.38</td>\n      <td>0.38</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.38</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.061</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>2.953</td>\n      <td>34</td>\n      <td>127</td>\n    </tr>\n    <tr>\n      <th>3391</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>2.333</td>\n      <td>5</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1445</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.73</td>\n      <td>0.0</td>\n      <td>0.36</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.604</td>\n      <td>0.181</td>\n      <td>0.000</td>\n      <td>3.787</td>\n      <td>58</td>\n      <td>356</td>\n    </tr>\n    <tr>\n      <th>1446</th>\n      <td>0.26</td>\n      <td>0.72</td>\n      <td>0.85</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.19</td>\n      <td>0.06</td>\n      <td>0.33</td>\n      <td>0.72</td>\n      <td>0.46</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.131</td>\n      <td>0.000</td>\n      <td>0.101</td>\n      <td>0.101</td>\n      <td>0.202</td>\n      <td>4.398</td>\n      <td>79</td>\n      <td>1280</td>\n    </tr>\n    <tr>\n      <th>1447</th>\n      <td>0.00</td>\n      <td>0.47</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.94</td>\n      <td>0.00</td>\n      <td>0.94</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.074</td>\n      <td>0.074</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>2.125</td>\n      <td>11</td>\n      <td>102</td>\n    </tr>\n    <tr>\n      <th>1448</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.96</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.163</td>\n      <td>0.489</td>\n      <td>0.000</td>\n      <td>0.326</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>2.300</td>\n      <td>12</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>1449</th>\n      <td>0.54</td>\n      <td>0.13</td>\n      <td>0.38</td>\n      <td>0.0</td>\n      <td>0.05</td>\n      <td>0.19</td>\n      <td>0.00</td>\n      <td>0.05</td>\n      <td>0.35</td>\n      <td>0.16</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.086</td>\n      <td>0.000</td>\n      <td>0.273</td>\n      <td>0.150</td>\n      <td>0.159</td>\n      <td>6.789</td>\n      <td>195</td>\n      <td>3327</td>\n    </tr>\n  </tbody>\n</table>\n<p>2900 rows × 57 columns</p>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Undersampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "ros = RandomUnderSampler(random_state=42, sampling_strategy='majority')\n",
    "x_resample_under, y_resample_under = ros.fit_resample(x_train, y_train)\n",
    "x_resample_under"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": "LogisticRegression(max_iter=500)",
      "text/html": "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=500)</pre></div></div></div></div></div>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression with Oversampling\n",
    "\n",
    "lr_reg = LogisticRegression(max_iter=500)\n",
    "lr_reg.fit(x_resample_under, y_resample_under)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "              Value\nAccuracy   0.931034\nRecall     0.922069\nPrecision  0.938904\nF1-score   0.930411",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Accuracy</th>\n      <td>0.931034</td>\n    </tr>\n    <tr>\n      <th>Recall</th>\n      <td>0.922069</td>\n    </tr>\n    <tr>\n      <th>Precision</th>\n      <td>0.938904</td>\n    </tr>\n    <tr>\n      <th>F1-score</th>\n      <td>0.930411</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluation of training set for Undersampling\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
    "y_resample_under_pred = lr_reg.predict(x_resample_under)\n",
    "\n",
    "accuracy = accuracy_score(y_resample_under, y_resample_under_pred)\n",
    "recall = recall_score(y_resample_under, y_resample_under_pred)\n",
    "precision = precision_score(y_resample_under, y_resample_under_pred)\n",
    "f1_score = f1_score(y_resample_under, y_resample_under_pred)\n",
    "\n",
    "errors = pd.DataFrame({'Value': [accuracy, recall, precision, f1_score]}, index=['Accuracy', 'Recall', 'Precision', 'F1-score'])\n",
    "errors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression(class_weight='balanced', solver='newton-cg')",
      "text/html": "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, solver=&#x27;newton-cg&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, solver=&#x27;newton-cg&#x27;)</pre></div></div></div></div></div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression with weighted Loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_reg = LogisticRegression(solver='newton-cg', class_weight='balanced')\n",
    "lr_reg.fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "              Value\nAccuracy   0.935598\nRecall     0.926207\nPrecision  0.911745\nF1-score   0.918919",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Accuracy</th>\n      <td>0.935598</td>\n    </tr>\n    <tr>\n      <th>Recall</th>\n      <td>0.926207</td>\n    </tr>\n    <tr>\n      <th>Precision</th>\n      <td>0.911745</td>\n    </tr>\n    <tr>\n      <th>F1-score</th>\n      <td>0.918919</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluation of training set for weighted loss\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
    "y_weighted_pred = lr_reg.predict(x_train)\n",
    "\n",
    "accuracy = accuracy_score(y_train, y_weighted_pred)\n",
    "recall = recall_score(y_train, y_weighted_pred)\n",
    "precision = precision_score(y_train, y_weighted_pred)\n",
    "f1_score = f1_score(y_train, y_weighted_pred)\n",
    "\n",
    "errors = pd.DataFrame({'Value': [accuracy, recall, precision, f1_score]}, index=['Accuracy', 'Recall', 'Precision', 'F1-score'])\n",
    "errors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}