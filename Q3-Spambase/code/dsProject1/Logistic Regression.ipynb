{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../../train.csv')\n",
    "test_data = pd.read_csv('../../test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set ->  False\n",
      "test set ->  False\n"
     ]
    }
   ],
   "source": [
    "#checking NAN values\n",
    "print('train set -> ', any(train_data.isnull().any()))\n",
    "print('test set -> ', any(test_data.isnull().any()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n0               0.33               0.00           0.67           0.0   \n1               0.00               0.00           0.00           0.0   \n2               0.08               0.08           0.76           0.0   \n3               0.05               0.05           0.40           0.0   \n4               0.00               0.00           0.84           0.0   \n...              ...                ...            ...           ...   \n3675            0.00               0.00           0.00           0.0   \n3676            0.00               0.00           0.66           0.0   \n3677            0.00               0.00           0.00           0.0   \n3678            0.00               0.00           0.00           0.0   \n3679            0.00               0.00           0.00           0.0   \n\n      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n0              0.22            0.00              0.00                0.00   \n1              0.00            0.00              0.00                0.00   \n2              0.85            1.02              0.25                0.17   \n3              0.34            0.00              0.00                0.00   \n4              0.56            0.00              0.00                0.56   \n...             ...             ...               ...                 ...   \n3675           0.00            0.00              0.00                0.00   \n3676           0.00            0.00              0.00                0.00   \n3677           0.00            0.00              0.00                0.00   \n3678           0.00            0.60              0.00                0.00   \n3679           0.00            0.00              0.00                0.00   \n\n      word_freq_order  word_freq_mail  ...  char_freq_;  char_freq_(  \\\n0                0.44            0.11  ...        0.000        0.157   \n1                0.00            0.00  ...        0.000        0.000   \n2                0.59            0.08  ...        0.000        0.065   \n3                0.57            0.05  ...        0.019        0.099   \n4                0.00            0.00  ...        0.000        0.278   \n...               ...             ...  ...          ...          ...   \n3675             0.00            0.00  ...        0.000        0.000   \n3676             0.00            0.00  ...        0.000        0.104   \n3677             0.00            0.00  ...        0.208        0.671   \n3678             0.00            0.60  ...        0.094        0.000   \n3679             0.00            0.00  ...        0.000        0.000   \n\n      char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n0           0.000        0.392        0.176        0.078   \n1           0.000        0.145        0.291        0.000   \n2           0.000        0.403        0.117        0.013   \n3           0.000        0.099        0.079        0.009   \n4           0.000        0.046        0.000        0.000   \n...           ...          ...          ...          ...   \n3675        0.000        0.595        0.000        0.000   \n3676        0.209        0.104        0.000        0.000   \n3677        0.092        0.000        0.000        0.000   \n3678        0.000        0.094        0.189        0.000   \n3679        0.000        0.000        0.000        0.000   \n\n      capital_run_length_average  capital_run_length_longest  \\\n0                          2.606                          75   \n1                          2.500                          11   \n2                          7.484                         669   \n3                          4.881                          95   \n4                          1.661                           6   \n...                          ...                         ...   \n3675                       1.500                           4   \n3676                       2.152                          17   \n3677                       4.122                          20   \n3678                       1.976                          15   \n3679                       1.250                           2   \n\n      capital_run_length_total  Class  \n0                          391      1  \n1                           45      1  \n2                         1407      1  \n3                         1313      1  \n4                          118      1  \n...                        ...    ...  \n3675                        15      0  \n3676                       127      0  \n3677                       540      0  \n3678                        83      0  \n3679                         5      0  \n\n[3680 rows x 58 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word_freq_make</th>\n      <th>word_freq_address</th>\n      <th>word_freq_all</th>\n      <th>word_freq_3d</th>\n      <th>word_freq_our</th>\n      <th>word_freq_over</th>\n      <th>word_freq_remove</th>\n      <th>word_freq_internet</th>\n      <th>word_freq_order</th>\n      <th>word_freq_mail</th>\n      <th>...</th>\n      <th>char_freq_;</th>\n      <th>char_freq_(</th>\n      <th>char_freq_[</th>\n      <th>char_freq_!</th>\n      <th>char_freq_$</th>\n      <th>char_freq_#</th>\n      <th>capital_run_length_average</th>\n      <th>capital_run_length_longest</th>\n      <th>capital_run_length_total</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.33</td>\n      <td>0.00</td>\n      <td>0.67</td>\n      <td>0.0</td>\n      <td>0.22</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.44</td>\n      <td>0.11</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.157</td>\n      <td>0.000</td>\n      <td>0.392</td>\n      <td>0.176</td>\n      <td>0.078</td>\n      <td>2.606</td>\n      <td>75</td>\n      <td>391</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.145</td>\n      <td>0.291</td>\n      <td>0.000</td>\n      <td>2.500</td>\n      <td>11</td>\n      <td>45</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.08</td>\n      <td>0.08</td>\n      <td>0.76</td>\n      <td>0.0</td>\n      <td>0.85</td>\n      <td>1.02</td>\n      <td>0.25</td>\n      <td>0.17</td>\n      <td>0.59</td>\n      <td>0.08</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.065</td>\n      <td>0.000</td>\n      <td>0.403</td>\n      <td>0.117</td>\n      <td>0.013</td>\n      <td>7.484</td>\n      <td>669</td>\n      <td>1407</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.05</td>\n      <td>0.05</td>\n      <td>0.40</td>\n      <td>0.0</td>\n      <td>0.34</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.57</td>\n      <td>0.05</td>\n      <td>...</td>\n      <td>0.019</td>\n      <td>0.099</td>\n      <td>0.000</td>\n      <td>0.099</td>\n      <td>0.079</td>\n      <td>0.009</td>\n      <td>4.881</td>\n      <td>95</td>\n      <td>1313</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.84</td>\n      <td>0.0</td>\n      <td>0.56</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.56</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.278</td>\n      <td>0.000</td>\n      <td>0.046</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.661</td>\n      <td>6</td>\n      <td>118</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3675</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.595</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.500</td>\n      <td>4</td>\n      <td>15</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3676</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.66</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.104</td>\n      <td>0.209</td>\n      <td>0.104</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>2.152</td>\n      <td>17</td>\n      <td>127</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3677</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.208</td>\n      <td>0.671</td>\n      <td>0.092</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>4.122</td>\n      <td>20</td>\n      <td>540</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3678</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.60</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.60</td>\n      <td>...</td>\n      <td>0.094</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.094</td>\n      <td>0.189</td>\n      <td>0.000</td>\n      <td>1.976</td>\n      <td>15</td>\n      <td>83</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3679</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.250</td>\n      <td>2</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3680 rows × 58 columns</p>\n</div>"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "# splitting Data sets\n",
    "x_train = train_data.drop(columns='Class')\n",
    "y_train = train_data['Class']\n",
    "\n",
    "x_test = test_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n0               0.33               0.00           0.67           0.0   \n1               0.00               0.00           0.00           0.0   \n2               0.08               0.08           0.76           0.0   \n3               0.05               0.05           0.40           0.0   \n4               0.00               0.00           0.84           0.0   \n...              ...                ...            ...           ...   \n4455            0.00               0.00           0.57           0.0   \n4456            0.00               0.42           0.42           0.0   \n4457            0.31               0.20           0.72           0.0   \n4458            0.56               0.00           0.84           0.0   \n4459            0.00               0.18           1.10           0.0   \n\n      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n0              0.22            0.00              0.00                0.00   \n1              0.00            0.00              0.00                0.00   \n2              0.85            1.02              0.25                0.17   \n3              0.34            0.00              0.00                0.00   \n4              0.56            0.00              0.00                0.56   \n...             ...             ...               ...                 ...   \n4455           0.28            0.00              0.00                0.57   \n4456           0.00            0.00              0.00                0.00   \n4457           0.00            0.62              0.00                0.62   \n4458           0.28            0.84              0.00                0.84   \n4459           0.73            0.73              0.73                0.09   \n\n      word_freq_order  word_freq_mail  ...  word_freq_conference  char_freq_;  \\\n0                0.44            0.11  ...                   0.0        0.000   \n1                0.00            0.00  ...                   0.0        0.000   \n2                0.59            0.08  ...                   0.0        0.000   \n3                0.57            0.05  ...                   0.0        0.019   \n4                0.00            0.00  ...                   0.0        0.000   \n...               ...             ...  ...                   ...          ...   \n4455             0.00            0.00  ...                   0.0        0.000   \n4456             0.00            0.00  ...                   0.0        0.000   \n4457             0.62            0.93  ...                   0.0        0.000   \n4458             0.28            0.28  ...                   0.0        0.000   \n4459             0.83            0.27  ...                   0.0        0.000   \n\n      char_freq_(  char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n0           0.157          0.0        0.392        0.176        0.078   \n1           0.000          0.0        0.145        0.291        0.000   \n2           0.065          0.0        0.403        0.117        0.013   \n3           0.099          0.0        0.099        0.079        0.009   \n4           0.278          0.0        0.046        0.000        0.000   \n...           ...          ...          ...          ...          ...   \n4455        0.047          0.0        1.147        0.191        0.191   \n4456        0.075          0.0        0.600        0.300        0.000   \n4457        0.000          0.0        0.548        0.199        0.033   \n4458        0.128          0.0        1.289        0.042        0.000   \n4459        0.094          0.0        0.430        0.134        0.013   \n\n      capital_run_length_average  capital_run_length_longest  \\\n0                          2.606                          75   \n1                          2.500                          11   \n2                          7.484                         669   \n3                          4.881                          95   \n4                          1.661                           6   \n...                          ...                         ...   \n4455                      11.735                         489   \n4456                       4.020                          82   \n4457                      14.283                         685   \n4458                       3.979                          47   \n4459                       8.445                         696   \n\n      capital_run_length_total  \n0                          391  \n1                           45  \n2                         1407  \n3                         1313  \n4                          118  \n...                        ...  \n4455                       622  \n4456                       197  \n4457                      1514  \n4458                       386  \n4459                      1478  \n\n[4460 rows x 57 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word_freq_make</th>\n      <th>word_freq_address</th>\n      <th>word_freq_all</th>\n      <th>word_freq_3d</th>\n      <th>word_freq_our</th>\n      <th>word_freq_over</th>\n      <th>word_freq_remove</th>\n      <th>word_freq_internet</th>\n      <th>word_freq_order</th>\n      <th>word_freq_mail</th>\n      <th>...</th>\n      <th>word_freq_conference</th>\n      <th>char_freq_;</th>\n      <th>char_freq_(</th>\n      <th>char_freq_[</th>\n      <th>char_freq_!</th>\n      <th>char_freq_$</th>\n      <th>char_freq_#</th>\n      <th>capital_run_length_average</th>\n      <th>capital_run_length_longest</th>\n      <th>capital_run_length_total</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.33</td>\n      <td>0.00</td>\n      <td>0.67</td>\n      <td>0.0</td>\n      <td>0.22</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.44</td>\n      <td>0.11</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.157</td>\n      <td>0.0</td>\n      <td>0.392</td>\n      <td>0.176</td>\n      <td>0.078</td>\n      <td>2.606</td>\n      <td>75</td>\n      <td>391</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.145</td>\n      <td>0.291</td>\n      <td>0.000</td>\n      <td>2.500</td>\n      <td>11</td>\n      <td>45</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.08</td>\n      <td>0.08</td>\n      <td>0.76</td>\n      <td>0.0</td>\n      <td>0.85</td>\n      <td>1.02</td>\n      <td>0.25</td>\n      <td>0.17</td>\n      <td>0.59</td>\n      <td>0.08</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.065</td>\n      <td>0.0</td>\n      <td>0.403</td>\n      <td>0.117</td>\n      <td>0.013</td>\n      <td>7.484</td>\n      <td>669</td>\n      <td>1407</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.05</td>\n      <td>0.05</td>\n      <td>0.40</td>\n      <td>0.0</td>\n      <td>0.34</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.57</td>\n      <td>0.05</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.019</td>\n      <td>0.099</td>\n      <td>0.0</td>\n      <td>0.099</td>\n      <td>0.079</td>\n      <td>0.009</td>\n      <td>4.881</td>\n      <td>95</td>\n      <td>1313</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.84</td>\n      <td>0.0</td>\n      <td>0.56</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.56</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.278</td>\n      <td>0.0</td>\n      <td>0.046</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>1.661</td>\n      <td>6</td>\n      <td>118</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4455</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.57</td>\n      <td>0.0</td>\n      <td>0.28</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.57</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.047</td>\n      <td>0.0</td>\n      <td>1.147</td>\n      <td>0.191</td>\n      <td>0.191</td>\n      <td>11.735</td>\n      <td>489</td>\n      <td>622</td>\n    </tr>\n    <tr>\n      <th>4456</th>\n      <td>0.00</td>\n      <td>0.42</td>\n      <td>0.42</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.075</td>\n      <td>0.0</td>\n      <td>0.600</td>\n      <td>0.300</td>\n      <td>0.000</td>\n      <td>4.020</td>\n      <td>82</td>\n      <td>197</td>\n    </tr>\n    <tr>\n      <th>4457</th>\n      <td>0.31</td>\n      <td>0.20</td>\n      <td>0.72</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.62</td>\n      <td>0.00</td>\n      <td>0.62</td>\n      <td>0.62</td>\n      <td>0.93</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>0.548</td>\n      <td>0.199</td>\n      <td>0.033</td>\n      <td>14.283</td>\n      <td>685</td>\n      <td>1514</td>\n    </tr>\n    <tr>\n      <th>4458</th>\n      <td>0.56</td>\n      <td>0.00</td>\n      <td>0.84</td>\n      <td>0.0</td>\n      <td>0.28</td>\n      <td>0.84</td>\n      <td>0.00</td>\n      <td>0.84</td>\n      <td>0.28</td>\n      <td>0.28</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.128</td>\n      <td>0.0</td>\n      <td>1.289</td>\n      <td>0.042</td>\n      <td>0.000</td>\n      <td>3.979</td>\n      <td>47</td>\n      <td>386</td>\n    </tr>\n    <tr>\n      <th>4459</th>\n      <td>0.00</td>\n      <td>0.18</td>\n      <td>1.10</td>\n      <td>0.0</td>\n      <td>0.73</td>\n      <td>0.73</td>\n      <td>0.73</td>\n      <td>0.09</td>\n      <td>0.83</td>\n      <td>0.27</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.094</td>\n      <td>0.0</td>\n      <td>0.430</td>\n      <td>0.134</td>\n      <td>0.013</td>\n      <td>8.445</td>\n      <td>696</td>\n      <td>1478</td>\n    </tr>\n  </tbody>\n</table>\n<p>4460 rows × 57 columns</p>\n</div>"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Oversampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=42, sampling_strategy='minority')\n",
    "x_resample_over, y_resample_over = ros.fit_resample(x_train, y_train)\n",
    "x_resample_over"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": "LogisticRegression(max_iter=500)",
      "text/html": "<style>#sk-container-id-17 {color: black;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=500)</pre></div></div></div></div></div>"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression with Oversampling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_reg_ov = LogisticRegression(max_iter=500)\n",
    "lr_reg_ov.fit(x_resample_over, y_resample_over)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "              Value\nAccuracy   0.934081\nRecall     0.924664\nPrecision  0.942413\nF1-score   0.933454",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Accuracy</th>\n      <td>0.934081</td>\n    </tr>\n    <tr>\n      <th>Recall</th>\n      <td>0.924664</td>\n    </tr>\n    <tr>\n      <th>Precision</th>\n      <td>0.942413</td>\n    </tr>\n    <tr>\n      <th>F1-score</th>\n      <td>0.933454</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluation of training set for Oversampling\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
    "y_resample_over_pred = lr_reg_ov.predict(x_resample_over)\n",
    "\n",
    "accuracy = accuracy_score(y_resample_over, y_resample_over_pred)\n",
    "recall = recall_score(y_resample_over, y_resample_over_pred)\n",
    "precision = precision_score(y_resample_over, y_resample_over_pred)\n",
    "f1_score = f1_score(y_resample_over, y_resample_over_pred)\n",
    "\n",
    "errors = pd.DataFrame({'Value': [accuracy, recall, precision, f1_score]}, index=['Accuracy', 'Recall', 'Precision', 'F1-score'])\n",
    "errors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confusion_matrix for oversampling\n",
    "cm = confusion_matrix(y_resample_over, y_resample_over_pred)\n",
    "sns.heatmap(cm/np.sum(cm), annot=True,\n",
    "            fmt='.2%', cmap='Blues')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n1506            1.04               0.00           0.52           0.0   \n2031            0.00               0.00           0.00           0.0   \n2209            0.00               0.00           0.00           0.0   \n2698            0.00               0.00           0.38           0.0   \n3391            0.00               0.00           0.00           0.0   \n...              ...                ...            ...           ...   \n1445            0.00               0.00           0.73           0.0   \n1446            0.26               0.72           0.85           0.0   \n1447            0.00               0.47           0.00           0.0   \n1448            0.00               0.00           0.00           0.0   \n1449            0.54               0.13           0.38           0.0   \n\n      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n1506           0.52            0.00              0.00                0.00   \n2031           0.00            0.00              0.00                0.00   \n2209           0.00            0.00              0.00                0.00   \n2698           0.38            0.38              0.00                0.00   \n3391           0.00            0.00              0.00                0.00   \n...             ...             ...               ...                 ...   \n1445           0.36            0.00              0.00                0.00   \n1446           0.00            0.19              0.06                0.33   \n1447           0.94            0.00              0.94                0.00   \n1448           0.00            0.00              1.96                0.00   \n1449           0.05            0.19              0.00                0.05   \n\n      word_freq_order  word_freq_mail  ...  word_freq_conference  char_freq_;  \\\n1506             0.00            0.00  ...                   0.0        0.000   \n2031             0.00            0.00  ...                   0.0        0.101   \n2209             0.00            0.00  ...                   0.0        0.000   \n2698             0.38            0.00  ...                   0.0        0.000   \n3391             0.00            0.00  ...                   0.0        0.000   \n...               ...             ...  ...                   ...          ...   \n1445             0.00            0.00  ...                   0.0        0.000   \n1446             0.72            0.46  ...                   0.0        0.000   \n1447             0.00            0.00  ...                   0.0        0.000   \n1448             0.00            0.00  ...                   0.0        0.163   \n1449             0.35            0.16  ...                   0.0        0.000   \n\n      char_freq_(  char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n1506        0.309        0.000        0.309        0.000        0.000   \n2031        0.254        0.101        0.050        0.050        0.000   \n2209        0.000        0.000        0.000        0.000        0.000   \n2698        0.061        0.000        0.000        0.000        0.000   \n3391        0.000        0.000        0.000        0.000        0.000   \n...           ...          ...          ...          ...          ...   \n1445        0.000        0.000        0.604        0.181        0.000   \n1446        0.131        0.000        0.101        0.101        0.202   \n1447        0.074        0.074        0.000        0.000        0.000   \n1448        0.489        0.000        0.326        0.000        0.000   \n1449        0.086        0.000        0.273        0.150        0.159   \n\n      capital_run_length_average  capital_run_length_longest  \\\n1506                       3.973                          34   \n2031                       2.725                          15   \n2209                       3.888                           8   \n2698                       2.953                          34   \n3391                       2.333                           5   \n...                          ...                         ...   \n1445                       3.787                          58   \n1446                       4.398                          79   \n1447                       2.125                          11   \n1448                       2.300                          12   \n1449                       6.789                         195   \n\n      capital_run_length_total  \n1506                       151  \n2031                       248  \n2209                        35  \n2698                       127  \n3391                         7  \n...                        ...  \n1445                       356  \n1446                      1280  \n1447                       102  \n1448                        46  \n1449                      3327  \n\n[2900 rows x 57 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word_freq_make</th>\n      <th>word_freq_address</th>\n      <th>word_freq_all</th>\n      <th>word_freq_3d</th>\n      <th>word_freq_our</th>\n      <th>word_freq_over</th>\n      <th>word_freq_remove</th>\n      <th>word_freq_internet</th>\n      <th>word_freq_order</th>\n      <th>word_freq_mail</th>\n      <th>...</th>\n      <th>word_freq_conference</th>\n      <th>char_freq_;</th>\n      <th>char_freq_(</th>\n      <th>char_freq_[</th>\n      <th>char_freq_!</th>\n      <th>char_freq_$</th>\n      <th>char_freq_#</th>\n      <th>capital_run_length_average</th>\n      <th>capital_run_length_longest</th>\n      <th>capital_run_length_total</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1506</th>\n      <td>1.04</td>\n      <td>0.00</td>\n      <td>0.52</td>\n      <td>0.0</td>\n      <td>0.52</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.309</td>\n      <td>0.000</td>\n      <td>0.309</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.973</td>\n      <td>34</td>\n      <td>151</td>\n    </tr>\n    <tr>\n      <th>2031</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.101</td>\n      <td>0.254</td>\n      <td>0.101</td>\n      <td>0.050</td>\n      <td>0.050</td>\n      <td>0.000</td>\n      <td>2.725</td>\n      <td>15</td>\n      <td>248</td>\n    </tr>\n    <tr>\n      <th>2209</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>3.888</td>\n      <td>8</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>2698</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.38</td>\n      <td>0.0</td>\n      <td>0.38</td>\n      <td>0.38</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.38</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.061</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>2.953</td>\n      <td>34</td>\n      <td>127</td>\n    </tr>\n    <tr>\n      <th>3391</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>2.333</td>\n      <td>5</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1445</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.73</td>\n      <td>0.0</td>\n      <td>0.36</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.604</td>\n      <td>0.181</td>\n      <td>0.000</td>\n      <td>3.787</td>\n      <td>58</td>\n      <td>356</td>\n    </tr>\n    <tr>\n      <th>1446</th>\n      <td>0.26</td>\n      <td>0.72</td>\n      <td>0.85</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.19</td>\n      <td>0.06</td>\n      <td>0.33</td>\n      <td>0.72</td>\n      <td>0.46</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.131</td>\n      <td>0.000</td>\n      <td>0.101</td>\n      <td>0.101</td>\n      <td>0.202</td>\n      <td>4.398</td>\n      <td>79</td>\n      <td>1280</td>\n    </tr>\n    <tr>\n      <th>1447</th>\n      <td>0.00</td>\n      <td>0.47</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.94</td>\n      <td>0.00</td>\n      <td>0.94</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.074</td>\n      <td>0.074</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>2.125</td>\n      <td>11</td>\n      <td>102</td>\n    </tr>\n    <tr>\n      <th>1448</th>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.96</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.163</td>\n      <td>0.489</td>\n      <td>0.000</td>\n      <td>0.326</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>2.300</td>\n      <td>12</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>1449</th>\n      <td>0.54</td>\n      <td>0.13</td>\n      <td>0.38</td>\n      <td>0.0</td>\n      <td>0.05</td>\n      <td>0.19</td>\n      <td>0.00</td>\n      <td>0.05</td>\n      <td>0.35</td>\n      <td>0.16</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000</td>\n      <td>0.086</td>\n      <td>0.000</td>\n      <td>0.273</td>\n      <td>0.150</td>\n      <td>0.159</td>\n      <td>6.789</td>\n      <td>195</td>\n      <td>3327</td>\n    </tr>\n  </tbody>\n</table>\n<p>2900 rows × 57 columns</p>\n</div>"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Undersampling\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "ros = RandomUnderSampler(random_state=42, sampling_strategy='majority')\n",
    "x_resample_under, y_resample_under = ros.fit_resample(x_train, y_train)\n",
    "x_resample_under"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": "LogisticRegression(max_iter=500)",
      "text/html": "<style>#sk-container-id-18 {color: black;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=500)</pre></div></div></div></div></div>"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression with Oversampling\n",
    "\n",
    "lr_reg_un = LogisticRegression(max_iter=500)\n",
    "lr_reg_un.fit(x_resample_under, y_resample_under)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "              Value\nAccuracy   0.931034\nRecall     0.922069\nPrecision  0.938904\nF1-score   0.930411",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Accuracy</th>\n      <td>0.931034</td>\n    </tr>\n    <tr>\n      <th>Recall</th>\n      <td>0.922069</td>\n    </tr>\n    <tr>\n      <th>Precision</th>\n      <td>0.938904</td>\n    </tr>\n    <tr>\n      <th>F1-score</th>\n      <td>0.930411</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluation of training set for Undersampling\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
    "y_resample_under_pred = lr_reg_un.predict(x_resample_under)\n",
    "\n",
    "accuracy = accuracy_score(y_resample_under, y_resample_under_pred)\n",
    "recall = recall_score(y_resample_under, y_resample_under_pred)\n",
    "precision = precision_score(y_resample_under, y_resample_under_pred)\n",
    "f1_score = f1_score(y_resample_under, y_resample_under_pred)\n",
    "\n",
    "errors = pd.DataFrame({'Value': [accuracy, recall, precision, f1_score]}, index=['Accuracy', 'Recall', 'Precision', 'F1-score'])\n",
    "errors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confusion_matrix for undersampling\n",
    "cm = confusion_matrix(y_resample_under, y_resample_under_pred)\n",
    "sns.heatmap(cm/np.sum(cm), annot=True,\n",
    "            fmt='.2%', cmap='Blues')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression(class_weight='balanced', solver='newton-cg')",
      "text/html": "<style>#sk-container-id-19 {color: black;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, solver=&#x27;newton-cg&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" checked><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, solver=&#x27;newton-cg&#x27;)</pre></div></div></div></div></div>"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression with weighted Loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_reg_wh = LogisticRegression(solver='newton-cg', class_weight='balanced')\n",
    "lr_reg_wh.fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "              Value\nAccuracy   0.935598\nRecall     0.926207\nPrecision  0.911745\nF1-score   0.918919",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Accuracy</th>\n      <td>0.935598</td>\n    </tr>\n    <tr>\n      <th>Recall</th>\n      <td>0.926207</td>\n    </tr>\n    <tr>\n      <th>Precision</th>\n      <td>0.911745</td>\n    </tr>\n    <tr>\n      <th>F1-score</th>\n      <td>0.918919</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluation of training set for weighted loss\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, precision_score\n",
    "y_weighted_pred = lr_reg_wh.predict(x_train)\n",
    "\n",
    "accuracy = accuracy_score(y_train, y_weighted_pred)\n",
    "recall = recall_score(y_train, y_weighted_pred)\n",
    "precision = precision_score(y_train, y_weighted_pred)\n",
    "f1_score = f1_score(y_train, y_weighted_pred)\n",
    "\n",
    "errors = pd.DataFrame({'Value': [accuracy, recall, precision, f1_score]}, index=['Accuracy', 'Recall', 'Precision', 'F1-score'])\n",
    "errors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}